# Daedalus Market Data Pipeline - systemd Service
# 
# This service runs the Daedalus supervisor which manages:
# - Ingestion pipeline (websocket collection)
# - Storage sync (local â†’ S3)
# - Health monitoring with auto-restart
# - Memory leak detection and forced restart
#
# Installation:
#   1. Copy this file to /etc/systemd/system/daedalus.service
#   2. **IMPORTANT**: Edit User, Group, and all paths to match YOUR system:
#      - User/Group: Your username (run `whoami` to check)
#      - WorkingDirectory: Path to your market-data-pipeline folder
#      - ExecStart: Path to your venv python and supervisor script
#   3. sudo systemctl daemon-reload
#   4. sudo systemctl enable daedalus
#   5. sudo systemctl start daedalus
#
# Management:
#   sudo systemctl status daedalus    # Check status
#   sudo systemctl stop daedalus      # Stop
#   sudo systemctl restart daedalus   # Restart
#   journalctl -u daedalus -f         # Follow logs
#   journalctl -u daedalus --since "1 hour ago"  # Recent logs
#
# Troubleshooting:
#   - "Failed to determine user credentials": Wrong User/Group - check `whoami`
#   - Check logs: tail -f /path/to/market-data-pipeline/logs/ingestion.log
#   - Check status: python scripts/daedalus_supervisor.py --status
#   - Memory issues: Check logs for "memory critical" messages

[Unit]
Description=Daedalus Market Data Pipeline Supervisor
Documentation=https://github.com/jp-quant/market-data-pipeline
After=network-online.target
Wants=network-online.target

[Service]
Type=simple

# ============================================================================
# IMPORTANT: UPDATE THESE VALUES TO MATCH YOUR SYSTEM
# ============================================================================
# Run `whoami` to get your username, then update User and Group
User=admin
Group=admin

# Update this to your actual project path
# Common locations:
#   /home/admin/Desktop/market-data-pipeline  (Pi4 with admin user)
#   /home/pi/market-data-pipeline             (Pi4 with pi user)
#   /home/username/market-data-pipeline       (other Linux)
WorkingDirectory=/home/admin/Desktop/market-data-pipeline

# Update paths to match WorkingDirectory above
ExecStart=/home/admin/Desktop/market-data-pipeline/venv/bin/python /home/admin/Desktop/market-data-pipeline/scripts/daedalus_supervisor.py
# ============================================================================

# Graceful shutdown with 60 second timeout
ExecStop=/bin/kill -SIGTERM $MAINPID
TimeoutStopSec=60

# Restart policy - systemd will restart the supervisor if it crashes
# The supervisor itself handles restarting ingestion/sync processes
Restart=always
RestartSec=30

# Resource limits to prevent Pi4 OOM
# The supervisor monitors individual process memory and restarts them if needed
MemoryMax=4G
MemoryHigh=3.5G

# Environment for memory optimization
Environment=PYTHONUNBUFFERED=1
Environment=MALLOC_ARENA_MAX=2
Environment=PYTHONMALLOC=malloc

# Logging - supervisor logs to stdout, journald captures it
StandardOutput=journal
StandardError=journal
SyslogIdentifier=daedalus

# Security hardening
NoNewPrivileges=true
PrivateTmp=true

# Capabilities needed for network access
AmbientCapabilities=CAP_NET_BIND_SERVICE

[Install]
WantedBy=multi-user.target
